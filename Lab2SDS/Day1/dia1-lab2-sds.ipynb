{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Instalando el SDK","metadata":{}},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:12:02.168561Z","iopub.execute_input":"2025-02-08T23:12:02.168995Z","iopub.status.idle":"2025-02-08T23:12:06.749962Z","shell.execute_reply.started":"2025-02-08T23:12:02.168962Z","shell.execute_reply":"2025-02-08T23:12:06.748756Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Importando lo anterior","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:12:10.570608Z","iopub.execute_input":"2025-02-08T23:12:10.570964Z","iopub.status.idle":"2025-02-08T23:12:10.576255Z","shell.execute_reply.started":"2025-02-08T23:12:10.570935Z","shell.execute_reply":"2025-02-08T23:12:10.574851Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:12:13.182268Z","iopub.execute_input":"2025-02-08T23:12:13.182707Z","iopub.status.idle":"2025-02-08T23:12:13.321889Z","shell.execute_reply.started":"2025-02-08T23:12:13.182674Z","shell.execute_reply":"2025-02-08T23:12:13.320490Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Corriendo el primer mensaje","metadata":{}},{"cell_type":"code","source":"flash = genai.GenerativeModel('gemini-1.5-flash')\nresponse = flash.generate_content(\"Explain AI to me like I'm a kid.\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:12:18.986296Z","iopub.execute_input":"2025-02-08T23:12:18.986670Z","iopub.status.idle":"2025-02-08T23:12:21.022543Z","shell.execute_reply.started":"2025-02-08T23:12:18.986641Z","shell.execute_reply":"2025-02-08T23:12:21.021374Z"}},"outputs":[{"name":"stdout","text":"Imagine you have a really smart puppy.  You teach it tricks, like \"sit\" and \"fetch\".  The more you teach it, the better it gets at those tricks, right?\n\nAI is kind of like that super smart puppy, but instead of tricks, it learns from information.  We give it lots and lots of information – pictures, words, numbers – and it learns to find patterns and do things with that information.\n\nSometimes it learns to recognize things in pictures, like cats or dogs.  Sometimes it learns to understand what you're saying and answer your questions.  Sometimes it even learns to play games better than you!\n\nIt's not actually *thinking* like a person, it's just really good at finding patterns and following instructions.  It's like a super-powered calculator that can do much more than just add and subtract.  It's still learning and getting better all the time!\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"Markdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:14:08.169374Z","iopub.execute_input":"2025-02-08T23:14:08.169848Z","iopub.status.idle":"2025-02-08T23:14:08.179029Z","shell.execute_reply.started":"2025-02-08T23:14:08.169813Z","shell.execute_reply":"2025-02-08T23:14:08.177616Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Imagine you have a really smart puppy.  You teach it tricks, like \"sit\" and \"fetch\".  The more you teach it, the better it gets at those tricks, right?\n\nAI is kind of like that super smart puppy, but instead of tricks, it learns from information.  We give it lots and lots of information – pictures, words, numbers – and it learns to find patterns and do things with that information.\n\nSometimes it learns to recognize things in pictures, like cats or dogs.  Sometimes it learns to understand what you're saying and answer your questions.  Sometimes it even learns to play games better than you!\n\nIt's not actually *thinking* like a person, it's just really good at finding patterns and following instructions.  It's like a super-powered calculator that can do much more than just add and subtract.  It's still learning and getting better all the time!\n"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Iniciando un chat","metadata":{}},{"cell_type":"code","source":"chat = flash.start_chat(history=[])\nresponse = chat.send_message('Hello! My name is Abner.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:15:49.531204Z","iopub.execute_input":"2025-02-08T23:15:49.531626Z","iopub.status.idle":"2025-02-08T23:15:50.296049Z","shell.execute_reply.started":"2025-02-08T23:15:49.531596Z","shell.execute_reply":"2025-02-08T23:15:50.294987Z"}},"outputs":[{"name":"stdout","text":"Hello Abner! It's nice to meet you.  How can I help you today?\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"response = chat.send_message('Can you tell something interesting about dinosaurs?')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:17:13.142740Z","iopub.execute_input":"2025-02-08T23:17:13.143173Z","iopub.status.idle":"2025-02-08T23:17:14.411152Z","shell.execute_reply.started":"2025-02-08T23:17:13.143142Z","shell.execute_reply":"2025-02-08T23:17:14.410145Z"}},"outputs":[{"name":"stdout","text":"Did you know that some dinosaurs had feathers?  While we often picture dinosaurs as scaly reptiles, many theropod dinosaurs (the group that includes *Tyrannosaurus rex*, but also smaller, bird-like dinosaurs) had feathers, ranging from simple filaments to complex, flight-capable feathers. This discovery significantly changed our understanding of dinosaur evolution and their relationship to modern birds.  In fact, birds are considered to be the direct descendants of theropod dinosaurs.\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# While you have the `chat` object around, the conversation state\n# persists. Confirm that by asking if it knows my name.\nresponse = chat.send_message('Do you remember what my name is?')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:18:06.158903Z","iopub.execute_input":"2025-02-08T23:18:06.159301Z","iopub.status.idle":"2025-02-08T23:18:06.755235Z","shell.execute_reply.started":"2025-02-08T23:18:06.159267Z","shell.execute_reply":"2025-02-08T23:18:06.754043Z"}},"outputs":[{"name":"stdout","text":"Yes, your name is Abner.\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Eligiendo un módelo","metadata":{}},{"cell_type":"code","source":"for model in genai.list_models():\n  print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:19:39.397270Z","iopub.execute_input":"2025-02-08T23:19:39.397716Z","iopub.status.idle":"2025-02-08T23:19:39.757333Z","shell.execute_reply.started":"2025-02-08T23:19:39.397681Z","shell.execute_reply":"2025-02-08T23:19:39.756186Z"}},"outputs":[{"name":"stdout","text":"models/chat-bison-001\nmodels/text-bison-001\nmodels/embedding-gecko-001\nmodels/gemini-1.0-pro-latest\nmodels/gemini-1.0-pro\nmodels/gemini-pro\nmodels/gemini-1.0-pro-001\nmodels/gemini-1.0-pro-vision-latest\nmodels/gemini-pro-vision\nmodels/gemini-1.5-pro-latest\nmodels/gemini-1.5-pro-001\nmodels/gemini-1.5-pro-002\nmodels/gemini-1.5-pro\nmodels/gemini-1.5-flash-latest\nmodels/gemini-1.5-flash-001\nmodels/gemini-1.5-flash-001-tuning\nmodels/gemini-1.5-flash\nmodels/gemini-1.5-flash-002\nmodels/gemini-1.5-flash-8b\nmodels/gemini-1.5-flash-8b-001\nmodels/gemini-1.5-flash-8b-latest\nmodels/gemini-1.5-flash-8b-exp-0827\nmodels/gemini-1.5-flash-8b-exp-0924\nmodels/gemini-2.0-flash-exp\nmodels/gemini-2.0-flash\nmodels/gemini-2.0-flash-001\nmodels/gemini-2.0-flash-lite-preview\nmodels/gemini-2.0-flash-lite-preview-02-05\nmodels/gemini-2.0-pro-exp\nmodels/gemini-2.0-pro-exp-02-05\nmodels/gemini-exp-1206\nmodels/gemini-2.0-flash-thinking-exp-01-21\nmodels/gemini-2.0-flash-thinking-exp\nmodels/gemini-2.0-flash-thinking-exp-1219\nmodels/learnlm-1.5-pro-experimental\nmodels/embedding-001\nmodels/text-embedding-004\nmodels/aqa\nmodels/imagen-3.0-generate-002\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"for model in genai.list_models():\n  if model.name == 'models/gemini-1.5-flash':\n    print(model)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:20:07.929375Z","iopub.execute_input":"2025-02-08T23:20:07.929874Z","iopub.status.idle":"2025-02-08T23:20:08.041704Z","shell.execute_reply.started":"2025-02-08T23:20:07.929833Z","shell.execute_reply":"2025-02-08T23:20:08.040253Z"}},"outputs":[{"name":"stdout","text":"Model(name='models/gemini-1.5-flash',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash',\n      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n      input_token_limit=1000000,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=40)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Explorando la generación de parametros","metadata":{}},{"cell_type":"code","source":"short_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(max_output_tokens=200))\n\nresponse = short_model.generate_content('Write a 1000 word essay on the importance of olives in modern society.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:21:43.113217Z","iopub.execute_input":"2025-02-08T23:21:43.113667Z","iopub.status.idle":"2025-02-08T23:21:44.900654Z","shell.execute_reply.started":"2025-02-08T23:21:43.113616Z","shell.execute_reply":"2025-02-08T23:21:44.899093Z"}},"outputs":[{"name":"stdout","text":"## The Enduring Importance of Olives in Modern Society\n\nThe olive, *Olea europaea*, a seemingly unassuming fruit, holds a position of remarkable significance in modern society, extending far beyond its culinary applications.  Its influence spans economic landscapes, cultural identities, and even ecological considerations. From the ancient Mediterranean to the globalized marketplace of the 21st century, the olive continues to exert a profound impact, highlighting the interconnectedness of agriculture, tradition, and contemporary life.\n\nOne of the most obvious aspects of the olive's importance lies in its economic contribution.  Olive cultivation, processing, and trade form a substantial sector in many countries, particularly in the Mediterranean region.  Spain, Italy, Greece, and Tunisia, among others, are major olive oil producers, with the industry providing livelihoods for millions of people involved in farming, harvesting, processing, and distribution. The economic impact extends beyond the immediate producers; it supports related industries such as packaging, transportation, and tourism.  \n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"response = short_model.generate_content('Write a short poem on the importance of olives in modern society.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:22:37.343762Z","iopub.execute_input":"2025-02-08T23:22:37.344144Z","iopub.status.idle":"2025-02-08T23:22:38.238216Z","shell.execute_reply.started":"2025-02-08T23:22:37.344113Z","shell.execute_reply":"2025-02-08T23:22:38.237071Z"}},"outputs":[{"name":"stdout","text":"From ancient groves, a modern grace,\nThe olive reigns, in time and place.\nIts oil, a gleam on countless plates,\nA taste of sun, that elevates.\n\nFrom skincare smooth to healthy heart,\nIt plays a role, a vital part.\nA symbol strong, of peace and might,\nThe olive shines, a constant light. \n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Probando mis propios prompt","metadata":{}},{"cell_type":"code","source":"response = short_model.generate_content('Describe a sunset in 20 words or less.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:25:49.790022Z","iopub.execute_input":"2025-02-08T23:25:49.790492Z","iopub.status.idle":"2025-02-08T23:25:50.325789Z","shell.execute_reply.started":"2025-02-08T23:25:49.790455Z","shell.execute_reply":"2025-02-08T23:25:50.324747Z"}},"outputs":[{"name":"stdout","text":"Crimson and gold bleed across the sky, painting clouds ablaze before night's embrace.\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"response = short_model.generate_content('Write a haiku about the beauty of the ocean.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:26:19.837731Z","iopub.execute_input":"2025-02-08T23:26:19.838099Z","iopub.status.idle":"2025-02-08T23:26:20.342124Z","shell.execute_reply.started":"2025-02-08T23:26:19.838069Z","shell.execute_reply":"2025-02-08T23:26:20.341196Z"}},"outputs":[{"name":"stdout","text":"Vast blue mystery,\nWaves crash on the sandy shore,\nOcean's breath so sweet. \n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"response = short_model.generate_content('What’s a simple way to reduce stress?')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:26:55.688868Z","iopub.execute_input":"2025-02-08T23:26:55.689248Z","iopub.status.idle":"2025-02-08T23:26:56.397377Z","shell.execute_reply.started":"2025-02-08T23:26:55.689218Z","shell.execute_reply":"2025-02-08T23:26:56.396168Z"}},"outputs":[{"name":"stdout","text":"Deep breathing.  Inhale slowly and deeply, hold for a few seconds, and exhale slowly.  Repeat several times.  It's simple, readily available, and can quickly calm your nervous system.\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Temperatura","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nfrom google.api_core import retry\n\n# Configurar la API Key\nfrom kaggle_secrets import UserSecretsClient\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Crear un modelo con temperatura alta (más aleatoriedad en las respuestas)\nhigh_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=2.0)\n)\n\n# Configurar política de reintento para evitar errores de cuota\nretry_policy = {\n    \"retry\": retry.Retry(predicate=retry.if_transient_error, initial=10, multiplier=1.5, timeout=300)\n}\n\n# Ejecutar la generación de respuestas 5 veces\nfor _ in range(5):\n    response = high_temp_model.generate_content(\n        'Pick a random colour... (respond in a single word)',\n        request_options=retry_policy\n    )\n    if response.parts:\n        print(response.text.strip(), '-' * 25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:29:49.149533Z","iopub.execute_input":"2025-02-08T23:29:49.150033Z","iopub.status.idle":"2025-02-08T23:29:51.921478Z","shell.execute_reply.started":"2025-02-08T23:29:49.149990Z","shell.execute_reply":"2025-02-08T23:29:51.920451Z"}},"outputs":[{"name":"stdout","text":"Maroon -------------------------\nMaroon -------------------------\nAquamarine -------------------------\nAquamarine -------------------------\nMarigold -------------------------\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Código con temperatura a 0","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nfrom google.api_core import retry\n\n# Configurar la API Key \nfrom kaggle_secrets import UserSecretsClient\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Crear un modelo con temperatura baja (más determinismo en las respuestas)\nlow_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=0.0)  # Determinista\n)\n\n# Configurar política de reintento para evitar errores de cuota\nretry_policy = {\n    \"retry\": retry.Retry(predicate=retry.if_transient_error, initial=10, multiplier=1.5, timeout=300)\n}\n\n# Ejecutar la generación de respuestas 5 veces\nfor _ in range(5):\n    response = low_temp_model.generate_content(\n        'Pick a random colour... (respond in a single word)',\n        request_options=retry_policy\n    )\n    if response.parts:\n        print(response.text.strip(), '-' * 25)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:31:37.268492Z","iopub.execute_input":"2025-02-08T23:31:37.268929Z","iopub.status.idle":"2025-02-08T23:31:39.818719Z","shell.execute_reply.started":"2025-02-08T23:31:37.268899Z","shell.execute_reply":"2025-02-08T23:31:39.817317Z"}},"outputs":[{"name":"stdout","text":"Maroon -------------------------\nMaroon -------------------------\nMaroon -------------------------\nMaroon -------------------------\nMaroon -------------------------\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Parámetros top-k y top-p","metadata":{}},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        # These are the default values for gemini-1.5-flash-001.\n        temperature=1.0,\n        top_k=64,\n        top_p=0.95,\n    ))\n\nstory_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\nresponse = model.generate_content(story_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:34:21.180848Z","iopub.execute_input":"2025-02-08T23:34:21.181188Z","iopub.status.idle":"2025-02-08T23:34:23.946590Z","shell.execute_reply.started":"2025-02-08T23:34:21.181163Z","shell.execute_reply":"2025-02-08T23:34:23.945275Z"}},"outputs":[{"name":"stdout","text":"Bartholomew, a ginger cat with a perpetual air of disdain, was bored. The usual routine of naps, snacks, and bird-watching had lost its charm. He yearned for something more, something... adventurous. \n\nOne day, while surveying his kingdom from atop the windowsill, Bartholomew spotted a peculiar sight. A bright yellow butterfly, unlike any he'd ever seen, flitted past the window, leaving a trail of shimmering dust in its wake. Curiosity gnawed at Bartholomew. He'd never seen such a creature before. \n\nDriven by a newfound sense of purpose, Bartholomew leaped onto the window ledge and, with a practiced agility, jumped out into the garden. He followed the butterfly, its wings a beacon in the afternoon sun. \n\nThe garden was a world of wonders. Lush flowers bloomed in vibrant hues, and a gentle breeze carried the scent of honeysuckle. But Bartholomew was focused on the butterfly. He chased it through a maze of fragrant bushes, his emerald eyes gleaming with excitement. \n\nSuddenly, the butterfly landed on a tall, swaying sunflower. Bartholomew crept closer, his tail twitching with anticipation. As he reached out to pounce, the butterfly unfurled its wings and, with a burst of color, vanished. In its place was a tiny, shimmering portal. \n\nIntrigued, Bartholomew peered through the portal. He saw a world unlike anything he'd ever imagined. Lush, green meadows stretched out before him, dotted with whimsical flowers and sparkling streams. In the distance, he saw majestic mountains that reached for the clouds. \n\nWithout hesitation, Bartholomew stepped through the portal. He found himself in a land teeming with friendly creatures. Squirrels chattered excitedly, birds serenaded him with beautiful melodies, and even a grumpy badger offered him a friendly nod. \n\nBartholomew explored this wondrous realm, his tail held high with pride. He learned the secrets of the forest, befriended a mischievous rabbit, and even shared a nap with a wise old owl. \n\nAfter a day of adventure, Bartholomew found himself longing for home. He returned to the portal, his heart brimming with joy. He stepped back into his own garden, transformed by his experience. \n\nFrom that day forward, Bartholomew wasn't just a cat who napped and ate. He was a cat who had ventured into a world beyond his wildest dreams, a cat who carried the memory of the magical butterfly and the wonders he had witnessed. He knew, deep within his feline heart, that the world held countless adventures waiting to be discovered, and he was ready for them all. \n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        # These are the default values for gemini-1.5-flash-001.\n        temperature=0.0,\n        top_k=60,\n        top_p=0.75,\n    ))\n\nstory_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\nresponse = model.generate_content(story_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:35:18.082752Z","iopub.execute_input":"2025-02-08T23:35:18.083134Z","iopub.status.idle":"2025-02-08T23:35:20.808369Z","shell.execute_reply.started":"2025-02-08T23:35:18.083104Z","shell.execute_reply":"2025-02-08T23:35:20.807182Z"}},"outputs":[{"name":"stdout","text":"Bartholomew, a ginger tabby with a penchant for mischief and a disdain for routine, was bored. The sunbeams that usually danced on his favorite rug were dull, the birds outside chirping the same monotonous tune. He yearned for something more, something… adventurous.\n\nHis opportunity arrived in the form of a delivery truck. The driver, a burly man with a booming laugh, carelessly left the back door ajar. Bartholomew, with the agility of a seasoned acrobat, slipped inside. The truck rumbled to life, and Bartholomew found himself on a journey unlike any he'd ever known.\n\nThe world outside his usual window was a kaleidoscope of sights and smells. He saw towering buildings that scraped the sky, bustling markets overflowing with exotic fruits, and a vast, shimmering ocean. He sniffed the scent of fresh bread, salty air, and the sweet perfume of blooming flowers.\n\nHis adventure took him to a bustling city park, where he encountered a group of pigeons. They were wary at first, but Bartholomew, with his charm and a few well-placed purrs, convinced them to share their crumbs. He even learned a few pigeon-speak phrases, which he found surprisingly useful.\n\nNext, he found himself in a cozy bookstore, where he spent hours curled up on a stack of dusty tomes, dreaming of faraway lands and mythical creatures. He even managed to snag a juicy mouse from the owner's lunch, a feat that earned him a scolding but also a grudging respect.\n\nAs the sun began to set, Bartholomew found himself back in his own neighborhood. The familiar scent of his home, the soft purr of the washing machine, and the comforting warmth of his favorite rug filled him with a sense of contentment.\n\nHe had seen the world, tasted its flavors, and learned its secrets. He had even made a few friends along the way. Bartholomew, the adventurous cat, had returned home a changed cat. He still enjoyed his naps in the sun, but now, he did so with a twinkle in his eye, a secret smile playing on his whiskered lips. He knew, deep down, that the world was a vast and wondrous place, and he was ready for his next adventure. \n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Prompt","metadata":{}},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=5,\n    ))\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Her\" is a disturbing study revealing the direction\nhumanity is headed if AI is allowed to keep evolving,\nunchecked. I wish there were more movies like this masterpiece.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:37:05.884657Z","iopub.execute_input":"2025-02-08T23:37:05.885088Z","iopub.status.idle":"2025-02-08T23:37:06.288262Z","shell.execute_reply.started":"2025-02-08T23:37:05.885055Z","shell.execute_reply":"2025-02-08T23:37:06.286992Z"}},"outputs":[{"name":"stdout","text":"Sentiment: **POSITIVE**\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        temperature=0.0,\n        top_p=1,\n        max_output_tokens=5,\n    ))\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Her\" is a disturbing study revealing the direction\nhumanity is headed if AI is allowed to keep evolving,\nunchecked. I wish there were more movies like this masterpiece.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:39:36.049935Z","iopub.execute_input":"2025-02-08T23:39:36.050337Z","iopub.status.idle":"2025-02-08T23:39:36.332726Z","shell.execute_reply.started":"2025-02-08T23:39:36.050310Z","shell.execute_reply":"2025-02-08T23:39:36.331662Z"}},"outputs":[{"name":"stdout","text":"Sentiment: **POSITIVE**\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=5,\n    ))\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"The Room\" is a complete disaster. The dialogue is awful, the acting is laughable, and the story makes no sense. \nIt’s painful to watch.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:39:52.703824Z","iopub.execute_input":"2025-02-08T23:39:52.704205Z","iopub.status.idle":"2025-02-08T23:39:53.036220Z","shell.execute_reply.started":"2025-02-08T23:39:52.704177Z","shell.execute_reply":"2025-02-08T23:39:53.035015Z"}},"outputs":[{"name":"stdout","text":"Sentiment: **NEGATIVE**\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Aplicando Enum","metadata":{}},{"cell_type":"code","source":"import enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ))\n\nresponse = model.generate_content(zero_shot_prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:41:32.173085Z","iopub.execute_input":"2025-02-08T23:41:32.173444Z","iopub.status.idle":"2025-02-08T23:41:32.502549Z","shell.execute_reply.started":"2025-02-08T23:41:32.173395Z","shell.execute_reply":"2025-02-08T23:41:32.501481Z"}},"outputs":[{"name":"stdout","text":"negative\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## Una respuesta o varias","metadata":{}},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=250,\n    ))\n\nfew_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"peperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a large with cheese & pineapple\"\n\n\nresponse = model.generate_content([few_shot_prompt, customer_order], request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:42:46.281006Z","iopub.execute_input":"2025-02-08T23:42:46.281570Z","iopub.status.idle":"2025-02-08T23:42:46.893805Z","shell.execute_reply.started":"2025-02-08T23:42:46.281521Z","shell.execute_reply":"2025-02-08T23:42:46.892787Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"size\": \"large\",\n  \"type\": \"normal\",\n  \"ingredients\": [\"cheese\", \"pineapple\"]\n}\n```\n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## Modo JSON","metadata":{}},{"cell_type":"code","source":"import typing_extensions as typing\n\nclass PizzaOrder(typing.TypedDict):\n    size: str\n    ingredients: list[str]\n    type: str\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        response_mime_type=\"application/json\",\n        response_schema=PizzaOrder,\n    ))\n\nresponse = model.generate_content(\"Can I have a large dessert pizza with apple and chocolate\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:44:57.063370Z","iopub.execute_input":"2025-02-08T23:44:57.063868Z","iopub.status.idle":"2025-02-08T23:44:58.127230Z","shell.execute_reply.started":"2025-02-08T23:44:57.063798Z","shell.execute_reply":"2025-02-08T23:44:58.126141Z"}},"outputs":[{"name":"stdout","text":"{\"ingredients\": [\"apple\", \"chocolate\"], \"size\": \"large\", \"type\": \"dessert pizza\"}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## Cadenas de pensamiento","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer directly.\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt, request_options=retry_policy)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:46:36.863215Z","iopub.execute_input":"2025-02-08T23:46:36.863584Z","iopub.status.idle":"2025-02-08T23:46:37.432536Z","shell.execute_reply.started":"2025-02-08T23:46:36.863557Z","shell.execute_reply":"2025-02-08T23:46:37.431342Z"}},"outputs":[{"name":"stdout","text":"47\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## Pensando paso a paso","metadata":{}},{"cell_type":"code","source":"prompt_step_by_step = \"\"\"When I was 4 years old, my partner was 3 times my age. \nNow, I am 20 years old. How old is my partner? Think step by step and return the answer.\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt_step_by_step, request_options=retry_policy)\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:47:55.368079Z","iopub.execute_input":"2025-02-08T23:47:55.368491Z","iopub.status.idle":"2025-02-08T23:47:56.656885Z","shell.execute_reply.started":"2025-02-08T23:47:55.368459Z","shell.execute_reply":"2025-02-08T23:47:56.655930Z"}},"outputs":[{"name":"stdout","text":"Here's how to solve this step-by-step:\n\n1. **Partner's age when you were 4:** When you were 4, your partner was 3 times your age, so they were 4 * 3 = 12 years old.\n\n2. **Age difference:** The age difference between you and your partner is 12 - 4 = 8 years.\n\n3. **Partner's current age:**  Since you are now 20, your partner is 20 + 8 = 28 years old.\n\nTherefore, your partner is now $\\boxed{28}$ years old.\n\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\nI am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n\nresponse = model.generate_content(prompt, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:48:23.886019Z","iopub.execute_input":"2025-02-08T23:48:23.886365Z","iopub.status.idle":"2025-02-08T23:48:25.337405Z","shell.execute_reply.started":"2025-02-08T23:48:23.886333Z","shell.execute_reply":"2025-02-08T23:48:25.336450Z"}},"outputs":[{"name":"stdout","text":"Step 1: Find the partner's age when you were 4.\n\n* When you were 4, your partner was 3 times your age, so they were 4 * 3 = 12 years old.\n\nStep 2: Find the age difference between you and your partner.\n\n* The age difference is 12 - 4 = 8 years.\n\nStep 3:  Determine your partner's current age.\n\n* You are now 20 years old.\n* The age difference remains constant.\n* Therefore, your partner is currently 20 + 8 = 28 years old.\n\nSo the answer is $\\boxed{28}$\n\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"## Probando esquemas de React","metadata":{}},{"cell_type":"code","source":"model_instructions = \"\"\"\nSolve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\nObservation is understanding relevant information from an Action's output and Action can be one of three types:\n (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n     will return some similar entities to search and you can try to search the information from those topics.\n (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n     so keep your searches short.\n (3) <finish>answer</finish>, which returns the answer and finishes the task.\n\"\"\"\n\nexample1 = \"\"\"Question\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n\nThought 1\nThe question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n\nAction 1\n<search>Milhouse</search>\n\nObservation 1\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n\nThought 2\nThe paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n\nAction 2\n<lookup>named after</lookup>\n\nObservation 2\nMilhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n\nThought 3\nMilhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n\nAction 3\n<finish>Richard Nixon</finish>\n\"\"\"\n\nexample2 = \"\"\"Question\nWhat is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n\nThought 1\nI need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n\nAction 1\n<search>Colorado orogeny</search>\n\nObservation 1\nThe Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought 2\nIt does not mention the eastern sector. So I need to look up eastern sector.\n\nAction 2\n<lookup>eastern sector</lookup>\n\nObservation 2\nThe eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought 3\nThe eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n\nAction 3\n<search>High Plains</search>\n\nObservation 3\nHigh Plains refers to one of two distinct land regions\n\nThought 4\nI need to instead search High Plains (United States).\n\nAction 4\n<search>High Plains (United States)</search>\n\nObservation 4\nThe High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n\nThought 5\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n\nAction 5\n<finish>1,800 to 7,000 ft</finish>\n\"\"\"\n\n# Come up with more examples yourself, or take a look through https://github.com/ysymyth/ReAct/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:51:18.940689Z","iopub.execute_input":"2025-02-08T23:51:18.941107Z","iopub.status.idle":"2025-02-08T23:51:18.946641Z","shell.execute_reply.started":"2025-02-08T23:51:18.941067Z","shell.execute_reply":"2025-02-08T23:51:18.945310Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"observation = \"\"\"Observation 1\n[1706.03762] Attention Is All You Need\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\"\"\"\n\n# Enviar el mensaje al modelo\nresponse = model.generate_content(observation, request_options=retry_policy)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:55:27.386109Z","iopub.execute_input":"2025-02-08T23:55:27.386487Z","iopub.status.idle":"2025-02-08T23:55:28.618736Z","shell.execute_reply.started":"2025-02-08T23:55:27.386460Z","shell.execute_reply":"2025-02-08T23:55:28.617557Z"}},"outputs":[{"name":"stdout","text":"This observation summarizes the key contribution of the groundbreaking paper \"Attention Is All You Need.\"  The core takeaway is the introduction of the Transformer architecture, a novel neural network design that relies *exclusively* on attention mechanisms for processing sequential data.  This is a significant departure from previous approaches that heavily utilized recurrence (like RNNs) or convolutions (like CNNs).  The claim is that attention is sufficient, and potentially superior, for tasks previously dominated by these other methods.\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"## Solicitando código","metadata":{}},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=1,\n        top_p=1,\n        max_output_tokens=1024,\n    ))\n\n# Gemini 1.5 models are very chatty, so it helps to specify they stick to the code.\ncode_prompt = \"\"\"\nWrite a Python function to calculate the factorial of a number. No explanation, provide only the code.\n\"\"\"\n\nresponse = model.generate_content(code_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T23:59:34.133069Z","iopub.execute_input":"2025-02-08T23:59:34.133404Z","iopub.status.idle":"2025-02-08T23:59:34.941603Z","shell.execute_reply.started":"2025-02-08T23:59:34.133379Z","shell.execute_reply":"2025-02-08T23:59:34.940541Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\ndef factorial(n):\n  if n == 0:\n    return 1\n  else:\n    return n * factorial(n-1)\n```\n"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"## Ejecutando código","metadata":{}},{"cell_type":"code","source":"# Definir el modelo con la configuración correcta.\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest'\n)\n\n# El prompt más claro y detallado para obtener el cálculo correcto.\ncode_exec_prompt = \"\"\"\nCalculate the sum of the first 14 prime numbers. Only consider the odd primes, and make sure you count them all.\n\"\"\"\n\n# Realizar la consulta al modelo\nresponse = model.generate_content(code_exec_prompt, request_options=retry_policy)\n\n# Imprimir la respuesta del modelo\nprint(\"Generated Text and Code:\\n\", response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T00:14:03.513177Z","iopub.execute_input":"2025-02-09T00:14:03.513593Z","iopub.status.idle":"2025-02-09T00:14:05.152330Z","shell.execute_reply.started":"2025-02-09T00:14:03.513548Z","shell.execute_reply":"2025-02-09T00:14:05.151318Z"}},"outputs":[{"name":"stdout","text":"Generated Text and Code:\n The first 14 prime numbers are 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43.  However, the instructions specify to only consider the *odd* primes.  That means we exclude 2.\n\nSo we sum: 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 + 31 + 37 + 41 + 43 = 288\n\nTherefore, the sum of the first 14 odd prime numbers is $\\boxed{288}$.\n\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"for part in response.candidates[0].content.parts:\n  print(part)\n  print(\"-----\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T00:15:14.754270Z","iopub.execute_input":"2025-02-09T00:15:14.754672Z","iopub.status.idle":"2025-02-09T00:15:14.761633Z","shell.execute_reply.started":"2025-02-09T00:15:14.754639Z","shell.execute_reply":"2025-02-09T00:15:14.760187Z"}},"outputs":[{"name":"stdout","text":"text: \"The first 14 prime numbers are 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43.  However, the instructions specify to only consider the *odd* primes.  That means we exclude 2.\\n\\nSo we sum: 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 + 31 + 37 + 41 + 43 = 288\\n\\nTherefore, the sum of the first 14 odd prime numbers is $\\\\boxed{288}$.\\n\"\n\n-----\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## Explicando el código","metadata":{}},{"cell_type":"code","source":"file_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n\nexplain_prompt = f\"\"\"\nPlease explain what this file does at a very high level. What is it, and why would I use it?\n\n```\n{file_contents}\n```\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\n\nresponse = model.generate_content(explain_prompt, request_options=retry_policy)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T00:16:17.465158Z","iopub.execute_input":"2025-02-09T00:16:17.465693Z","iopub.status.idle":"2025-02-09T00:16:20.186141Z","shell.execute_reply.started":"2025-02-09T00:16:17.465649Z","shell.execute_reply":"2025-02-09T00:16:20.184946Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"This file is a Bash script that enhances your terminal prompt to display information about your current Git repository.  In essence, it's a **Git prompt customization script**.\n\nYou would use it to:\n\n* **Improve your Git workflow:**  By showing the current branch, changes (staged, unstaged, untracked files), ahead/behind status compared to the remote, and other relevant Git status information directly in your shell prompt, you gain a quick overview of your repository's state without having to explicitly run `git status`.\n\n* **Customize the appearance of your prompt:** The script allows you to choose from various pre-defined themes or create your own custom theme to control the colors and formatting of the displayed Git information.  This improves readability and aesthetics.\n\n* **Integrate with other tools:** It has provisions for handling virtual environments (like virtualenv, conda, or nvm), further contextualizing your prompt.\n\nIn short, it's a tool to make working with Git more efficient and visually appealing by integrating Git status directly into your shell prompt.\n"},"metadata":{}}],"execution_count":68}]}